{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining - Predictive Analytics for Hotel Reviews & Ratings\n",
    "#### (Dtree, Naive Bayes, Logistic regression, KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Project is an analysis on text data from hotel reviews using ML methods.\n",
    "The dataset for this assignment is from Kaggle.com it is reviews of hotels from the source TripAdvisor. Columns are the persons review and a rating scale from 1-5 with 5 being the best and 1 being the worst. (https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data selected for this assignment is consumer text reviews of hotels and the ratings that were given for these reviews. With this data we are hoping to predict the ratings and explore key aspects that make a hotel good or bad. The overall accuracy along with how precise the model can determine a 5 rating or 1 rating. Examining these areas along with sentiment analysis can be used to improve customer experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An score of 55% or more could be useful. This can be used by having consumers submit reviews to us during their stay and using the prediction of rating, adjustments can then be made for that customer in order to increase the rating score at the end of their stay that may be posted to trip advisor. Higher ratings can attract more customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive analysis methods applied were Decision Tree, Naive Bayes, Logistic Regression, K Nearest Neighbors. These were selected because the data is labeled supervised data and these methods are best applied to this type of data for training, testing and then in use for predictions. The model that performed best is the weighted Logistic Regression. (Tdif Vectorizer) This model had an overall accuracy of 61.5 and high precision and recall for 5 Ratings of 0.69 and .83 as well as high precision and recall for 1 Ratings of 0.75 and 0.61."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in or create a data frame with at least one column of text to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "pd.set_option('display.max_colwidth', 15000) #important for getting all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20491, 2)\n",
      "['Review', 'Rating']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/17857/OneDrive/Desktop/Text Mining 6304/tripadvisor_hotel_reviews.csv\") \n",
    "\n",
    "print(df.shape)\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the preprocessing steps you deem appropriate and append the results to your original data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20491, 52650)\n",
      "<class 'list'> 52650\n",
      "<class 'list'> 52650\n",
      "             count\n",
      "hotel        49814\n",
      "room         35331\n",
      "great        21475\n",
      "good         17412\n",
      "staff        16633\n",
      "stay         15411\n",
      "did          14006\n",
      "just         12667\n",
      "nice         12643\n",
      "rooms        12401\n",
      "location     11351\n",
      "stayed       10500\n",
      "service      10367\n",
      "night        10151\n",
      "time         10120\n",
      "beach        10061\n",
      "day           9967\n",
      "breakfast     9737\n",
      "clean         9597\n",
      "food          9412\n",
      "like          8254\n",
      "resort        8139\n",
      "place         7791\n",
      "really        7790\n",
      "pool          7577\n",
      "friendly      6893\n",
      "people        6836\n",
      "small         6595\n",
      "little        6260\n",
      "walk          6255\n",
      "got           6206\n",
      "excellent     6193\n",
      "area          6116\n",
      "best          5750\n",
      "helpful       5705\n",
      "bar           5573\n",
      "restaurant    5334\n",
      "restaurants   5142\n",
      "bathroom      5103\n",
      "water         5036\n"
     ]
    }
   ],
   "source": [
    "# quick peak at basic feature space\n",
    "prelim = CountVectorizer(binary=False, stop_words = 'english') \n",
    "prelim_dm = prelim.fit_transform(df['Review'])\n",
    "print(prelim_dm.shape)\n",
    "\n",
    "names = prelim.get_feature_names()\n",
    "print(type(names), len(names))\n",
    "\n",
    "count = np.sum(prelim_dm.toarray(), axis = 0).tolist()\n",
    "print(type(count), len(count))\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "print(count_df.sort_values(['count'], ascending = False).head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little preprocessing\n",
    "# custom dictionary to combine like terms\n",
    "import re\n",
    "reviews_dict = {'rooms':'room','restaurants':'restaurant', 'beds':'bed', 'bars':'bar','lots':'lot', 'little':'small'}\n",
    "\n",
    "\n",
    "def multiple_replace(dict, Review): \n",
    "\n",
    "  \"\"\" Replace in 'text' all occurences of any key in the given\n",
    "  dictionary by its corresponding value.  Returns the new string.\"\"\" \n",
    "  Review = str(Review).lower()\n",
    "\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], Review)\n",
    "\n",
    "df['cleanreview'] = df.Review.apply(lambda x: multiple_replace(reviews_dict, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "179\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "# create a stopwords list \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk_stopwords = stopwords.words(\"english\")\n",
    "my_stopwords = nltk_stopwords + [\"10\", \"15\", \"20\", '30', 'ca','got',]\n",
    "\n",
    "print(type(nltk_stopwords))\n",
    "print(len(nltk_stopwords))\n",
    "print(len(my_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Review', 'Rating', 'cleanreview']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20491, 1683)\n",
      "(20491, 1683)\n",
      "<class 'list'> 1683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# instantiate vectorizer(s)\n",
    "cv1 = CountVectorizer(lowercase=True, \n",
    "                     stop_words=my_stopwords,\n",
    "                     binary=False,\n",
    "                     max_df=0.99, \n",
    "                     min_df=0.01,\n",
    "                     ngram_range = (1,2)) \n",
    "tfidf1 = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words= my_stopwords, \n",
    "                        max_df=0.99, \n",
    "                        min_df=0.01,\n",
    "                        ngram_range = (1,2)) \n",
    "\n",
    "\n",
    "\n",
    "# fit and transform text\n",
    "cv_dm = cv1.fit_transform(df['cleanreview'])\n",
    "tfidf_dm = tfidf1.fit_transform(df['cleanreview'])\n",
    "\n",
    "\n",
    "# print matrix shape(s)\n",
    "print(cv_dm.shape)\n",
    "print(tfidf_dm.shape)\n",
    "names = cv1.get_feature_names()\n",
    "print(type(names), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1683\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hotel</th>\n",
       "      <td>49814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room</th>\n",
       "      <td>47732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>21475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>17412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staff</th>\n",
       "      <td>16633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay</th>\n",
       "      <td>15411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>12855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>12643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>11351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stayed</th>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restaurant</th>\n",
       "      <td>10476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>10367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>10151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>10120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beach</th>\n",
       "      <td>10061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>9967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>9597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>9412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>8254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resort</th>\n",
       "      <td>8139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>7791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>7790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed</th>\n",
       "      <td>7723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool</th>\n",
       "      <td>7577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>6941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friendly</th>\n",
       "      <td>6893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>6836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>6193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathroom</th>\n",
       "      <td>5993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>5705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lot</th>\n",
       "      <td>5138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip</th>\n",
       "      <td>5021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend</th>\n",
       "      <td>4865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>4734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>4729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "hotel       49814\n",
       "room        47732\n",
       "great       21475\n",
       "good        17412\n",
       "staff       16633\n",
       "stay        15411\n",
       "small       12855\n",
       "nice        12643\n",
       "location    11351\n",
       "stayed      10500\n",
       "restaurant  10476\n",
       "service     10367\n",
       "night       10151\n",
       "time        10120\n",
       "beach       10061\n",
       "day          9967\n",
       "breakfast    9737\n",
       "clean        9597\n",
       "food         9412\n",
       "like         8254\n",
       "resort       8139\n",
       "place        7791\n",
       "really       7790\n",
       "bed          7723\n",
       "pool         7577\n",
       "bar          6941\n",
       "friendly     6893\n",
       "people       6836\n",
       "walk         6255\n",
       "excellent    6193\n",
       "area         6116\n",
       "bathroom     5993\n",
       "best         5750\n",
       "helpful      5705\n",
       "lot          5138\n",
       "water        5036\n",
       "trip         5021\n",
       "recommend    4865\n",
       "beautiful    4734\n",
       "view         4729"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.sum(cv_dm.toarray(), axis = 0).tolist()\n",
    "print(type(count), len(count))\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(['count'], ascending = False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cv1.get_feature_names()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decided remove the two most commonly used words 'hotel' and 'room' because they may not have much use in predicting the rating of the review. Then went back and ran models again with these features included. It did not make a difference in the accuracy at all. I began with Max df at .95 and min df at .05. When I changed these to .90 and .10 the accuracy was worsened. I then adjusted to .80 and .20 and this was even worse. I then increased the Max Df to .99 and Min df to .01 and the accuracy here improved across the board.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9054</td>\n",
       "      <td>44.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6039</td>\n",
       "      <td>29.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2184</td>\n",
       "      <td>10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1793</td>\n",
       "      <td>8.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1421</td>\n",
       "      <td>6.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total      %\n",
       "5   9054  44.2%\n",
       "4   6039  29.5%\n",
       "3   2184  10.7%\n",
       "2   1793   8.8%\n",
       "1   1421   6.9%"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target variable is the ratings\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get a feel for the distribution\n",
    "df['Rating'].value_counts().plot(kind='bar')\n",
    "df.Rating.value_counts()\n",
    "r = df.Rating\n",
    "total = r.value_counts()\n",
    "percent = r.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "pd.DataFrame({'Total': total, '%': percent})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply at least two machine learning methods to make a prediction.\n",
    "\n",
    "### First create the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "<class 'numpy.ndarray'> [4 2 3 5 5 5 5 4 5 5]\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "print(type(X), X[0:10])\n",
    "\n",
    "\n",
    "y = df['Rating'].values #this is an array of labels\n",
    "print(type(y), y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14343, 1683)\n",
      "(6148, 1683)\n",
      "(14343,)\n",
      "(6148,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# 70% and 30% split\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide output that demonstrates the accuracy of your predictions (supervised) OR compares the distribution of class assignments (unsupervised)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4503903708523097\n",
      "accuracy: 0.4503903708523097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.43      0.45       432\n",
      "           2       0.22      0.19      0.20       523\n",
      "           3       0.19      0.19      0.19       645\n",
      "           4       0.39      0.39      0.39      1887\n",
      "           5       0.59      0.61      0.60      2661\n",
      "\n",
      "    accuracy                           0.45      6148\n",
      "   macro avg       0.37      0.36      0.37      6148\n",
      "weighted avg       0.45      0.45      0.45      6148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a Decision Tree model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "#print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45% Accuracy, Not too great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5844176968119714\n",
      "accuracy: 0.5844176968119714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.68      0.66       432\n",
      "           2       0.33      0.37      0.35       523\n",
      "           3       0.36      0.34      0.35       645\n",
      "           4       0.53      0.42      0.47      1887\n",
      "           5       0.70      0.79      0.74      2661\n",
      "\n",
      "    accuracy                           0.58      6148\n",
      "   macro avg       0.51      0.52      0.51      6148\n",
      "weighted avg       0.57      0.58      0.58      6148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "#print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58% Accuracy this is better High precision for 5 rating and 1 rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5826284970722186\n",
      "accuracy: 0.5826284970722186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.61      0.63       432\n",
      "           2       0.39      0.40      0.40       523\n",
      "           3       0.34      0.35      0.35       645\n",
      "           4       0.50      0.44      0.47      1887\n",
      "           5       0.70      0.77      0.74      2661\n",
      "\n",
      "    accuracy                           0.58      6148\n",
      "   macro avg       0.52      0.52      0.52      6148\n",
      "weighted avg       0.58      0.58      0.58      6148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17857\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression(random_state = 42, solver = 'lbfgs', multi_class = 'auto')\n",
    "#print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58% accuracy getting better High precision for 5 rating and 1 rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Weights Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.06140346 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "<class 'numpy.ndarray'> [4 2 3 5 5 5 5 4 5 5]\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tfidf_dm.toarray()  #remember this is the output from the vectorizer\n",
    "print(type(X), X[0:10])\n",
    "\n",
    "\n",
    "y = df['Rating'].values #this is an array of labels\n",
    "print(type(y), y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14343, 1683)\n",
      "(6148, 1683)\n",
      "(14343,)\n",
      "(6148,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "#70% and 30% split\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44469746258945997\n",
      "accuracy: 0.44469746258945997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.37      0.40       432\n",
      "           2       0.21      0.21      0.21       523\n",
      "           3       0.20      0.20      0.20       645\n",
      "           4       0.39      0.38      0.38      1887\n",
      "           5       0.58      0.61      0.60      2661\n",
      "\n",
      "    accuracy                           0.44      6148\n",
      "   macro avg       0.36      0.35      0.36      6148\n",
      "weighted avg       0.44      0.44      0.44      6148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a decision tree model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly increased accuracy as earlier model 45.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5673389720234222\n",
      "accuracy: 0.5673389720234222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.48      0.60       432\n",
      "           2       0.42      0.31      0.35       523\n",
      "           3       0.34      0.02      0.04       645\n",
      "           4       0.45      0.37      0.41      1887\n",
      "           5       0.62      0.90      0.73      2661\n",
      "\n",
      "    accuracy                           0.57      6148\n",
      "   macro avg       0.53      0.42      0.43      6148\n",
      "weighted avg       0.53      0.57      0.52      6148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "#print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreased accuracy from earlier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6136955107351985\n",
      "accuracy: 0.6136955107351985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.62      0.68       432\n",
      "           2       0.47      0.40      0.43       523\n",
      "           3       0.43      0.27      0.33       645\n",
      "           4       0.52      0.49      0.50      1887\n",
      "           5       0.69      0.83      0.75      2661\n",
      "\n",
      "    accuracy                           0.61      6148\n",
      "   macro avg       0.57      0.52      0.54      6148\n",
      "weighted avg       0.60      0.61      0.60      6148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17857\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression(random_state = 42, solver = 'lbfgs', multi_class = 'auto')\n",
    "#print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy seen so far 61.5% with highest 5 rating and 1 rating precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5253741054001301\n",
      "accuracy: 0.5253741054001301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.39      0.47       432\n",
      "           2       0.30      0.16      0.21       523\n",
      "           3       0.39      0.09      0.14       645\n",
      "           4       0.43      0.43      0.43      1887\n",
      "           5       0.59      0.80      0.68      2661\n",
      "\n",
      "    accuracy                           0.53      6148\n",
      "   macro avg       0.47      0.37      0.39      6148\n",
      "weighted avg       0.50      0.53      0.49      6148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loading library\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate learning model (k = x)\n",
    "model = KNeighborsClassifier(n_neighbors=19)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "knn1_expected = y_test\n",
    "knn1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(knn1_expected, knn1_predicted)))\n",
    "print(metrics.classification_report(knn1_expected, knn1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best KNN is 19 after trying many K but accuracy is slightly lower than some models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data selected for this assignment is consumer text reviews of hotels and the ratings that were given for these reviews.\n",
    "With this data we are hoping to predict the ratings and explore key aspects that make a hotel good or bad.\n",
    "The overall accuracy along with how precise the model can determine a 5 rating or 1 rating. Examining these areas along with\n",
    "sentiment analysis can be used to improve customer experience. An score of 55% or more could be useful.\n",
    "This can be used by having consumers submit reviews to us during their stay and using the prediction of rating, adjustments\n",
    "can then be made for that customer in order to increase the rating score at the end of their stay that may be posted to trip advisor. Higher ratings can attract more customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive analysis methods applied were Decision Tree, Naive Bayes, Logistic Regression, K Nearest Neighbors.\n",
    "These were selected because the data is labeled supervised data and these methods are best applied to this type of data\n",
    "for training, testing and then in use for predictions. The model that performed best is the weighted Logistic Regression. (Tdif Vectorizer)\n",
    "This model had an overall accuracy of 61.5 and high precision and recall for 5 Ratings of 0.69 and .83 as well as high precision\n",
    "and recall for 1 Ratings of 0.75 and 0.61.\n",
    "\n",
    "The most influential paramenters on the results were the Max Df and Min Df in the vectorizers.\n",
    "I began with Max df at .95 and min df at .05. When I changed these to .90 and .10 the accuracy was worsened. I then adjusted to .80 and .20 and this was even worse. \n",
    "I then increased the Max Df to .99 and Min df to .01 and the accuracy here improved across the board.\n",
    "Initially I decided remove the two most commonly used words 'hotel' and 'room' because they may not have much use in predicitng the rating of the review. \n",
    "Then went back and ran models again with these features included. It did not make a difference in the accuracy at all. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
